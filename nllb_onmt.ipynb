{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ML_yvSbJ-dRC"
      },
      "source": [
        "## Data preparation WORK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xl1q4Xu4CCFE"
      },
      "source": [
        "**Change according to your configuration, and environment**\n",
        "\n",
        "**Make sure there the 'scripts' folder and 'data' folder are presents.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8gBg9ONY9cf"
      },
      "outputs": [],
      "source": [
        "%pip install datasets OpenNMT-py sentencepiece sacrebleuq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhdA84QCD_-U"
      },
      "outputs": [],
      "source": [
        "!wget https://s3.amazonaws.com/opennmt-models/nllb-200/flores200_sacrebleu_tokenizer_spm.model -P data\n",
        "!wget https://s3.amazonaws.com/opennmt-models/nllb-200/nllb-inference.yaml\n",
        "!wget https://dl.fbaipublicfiles.com/large_objects/nllb/models/spm_200/dictionary.txt -P data\n",
        "!wget https://s3.amazonaws.com/opennmt-models/nllb-200/nllb-200-600M-onmt.pt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wfH0bTHDQYR"
      },
      "outputs": [],
      "source": [
        "# Cleaning task\n",
        "!python scripts/filter.py data/train.fr data/train.bam\n",
        "# Training the Sentence piece subwording models for French and Bam\n",
        "!python scripts/unigram.py data/train.fr.fil.txt data/train.bam.fil.txt\n",
        "# Deplacer les fichier créer par les différents scripts dans le dossier data\n",
        "!mv *.vocab *.model data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C52HNfyRDQYW"
      },
      "outputs": [],
      "source": [
        "# Subwording the train, test and dev sets\n",
        "!python scripts/subword.py data/source.model data/target.model data/train.fr.fil.txt data/train.bam.fil.txt\n",
        "!python scripts/subword.py data/source.model data/target.model data/dev.fr data/dev.bam\n",
        "!python scripts/subword.py data/source.model data/target.model data/test.fr data/test.bam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sHfEqPuDQYZ"
      },
      "outputs": [],
      "source": [
        "# Move the new created files in folder \"data\" and change their names\n",
        "!mv data/train.sub-src.txt data/train.sub.fr && mv data/train.sub-trg.txt data/train.sub.bam\n",
        "!mv data/dev.sub-src.txt data/dev.sub.fr && mv data/dev.sub-trg.txt data/dev.sub.bam\n",
        "!mv data/test.sub-src.txt data/test.sub.fr && mv data/test.sub-trg.txt data/test.sub.bam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!head -10 data/train.sub.fr data/train.sub.bam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31VoxzGqHY8d"
      },
      "source": [
        "## Model / Training Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1h408pBQY08H"
      },
      "outputs": [],
      "source": [
        "# Try to avoid running out of memory\n",
        "!export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6KKFqB0HeaH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "model_name = \"fr2bam\"\n",
        "vocab_size = 50000\n",
        "\n",
        "training_steps = 2500\n",
        "valid_steps = int(training_steps / 5)\n",
        "save_ckpt_freq = int(training_steps / 5)\n",
        "warmup_steps = int(training_steps / 10)\n",
        "reporting =  10 # int(training_steps/10)\n",
        "GPU = 1 # TOGGLE for GPU\n",
        "\n",
        "if(not os.path.exists(model_name)):\n",
        "  os.makedirs(model_name)\n",
        "\n",
        "config = f\"\"\"\n",
        "\n",
        "# config.yaml\n",
        "\n",
        "\n",
        "## Where the samples will be written\n",
        "save_data: run\n",
        "\n",
        "# Training files\n",
        "data:\n",
        "    corpus_1:\n",
        "        path_src: data/train.sub.fr\n",
        "        path_tgt: data/train.sub.bam\n",
        "        transforms: [filtertoolong] # change the transform method\n",
        "    valid:\n",
        "        path_src: data/dev.sub.fr\n",
        "        path_tgt: data/dev.sub.bam\n",
        "        transforms: [filtertoolong] # change the transform method\n",
        "\n",
        "# Vocabulary files, generated by onmt_build_vocab\n",
        "src_vocab: data/dictionary.txt\n",
        "tgt_vocab: data/dictionary.txt\n",
        "\n",
        "train_from: nllb-200-600M-onmt.pt\n",
        "\n",
        "# Vocabulary size - should be the same as in sentence piece\n",
        "src_vocab_size: 50000\n",
        "tgt_vocab_size: 50000\n",
        "\n",
        "# Filter out source/target longer than n if [filtertoolong] enabled\n",
        "src_seq_length: 200\n",
        "src_seq_length: 200\n",
        "\n",
        "# Tokenization options\n",
        "src_subword_model: data/flores200_sacrebleu_tokenizer_spm.model\n",
        "tgt_subword_model: data/flores200_sacrebleu_tokenizer_spm.model\n",
        "\n",
        "# Where to save the log file and the output models/checkpoints\n",
        "log_file: train.log\n",
        "save_model: models/{model_name}\n",
        "\n",
        "# Stop training if it does not imporve after n validations\n",
        "early_stopping: 3\n",
        "\n",
        "# Default: 5000 - Save a model checkpoint for each n\n",
        "save_checkpoint_steps: {save_ckpt_freq}\n",
        "\n",
        "# To save space, limit checkpoints to last n\n",
        "keep_checkpoint: 2\n",
        "\n",
        "seed: 3456\n",
        "\n",
        "# Default: 100000 - Train the model to max n steps \n",
        "# Increase to 200000 or more for large datasets\n",
        "# For fine-tuning, add up the required steps to the original steps\n",
        "train_steps: {training_steps}\n",
        "\n",
        "# Default: 10000 - Run validation after n steps\n",
        "valid_steps: {valid_steps}\n",
        "\n",
        "# Default: 4000 - for large datasets, try up to 8000\n",
        "warmup_steps: {warmup_steps}\n",
        "report_every: {reporting}\n",
        "\n",
        "# Batching\n",
        "num_workers: 2  # Default: 2, set to 0 when RAM out of memory\n",
        "batch_type: \"tokens\"\n",
        "batch_size: 512  # Tokens per batch, change when CUDA out of memory\n",
        "valid_batch_size: 512\n",
        "max_generator_batches: 2\n",
        "accum_count: [4]\n",
        "accum_steps: [0]\n",
        "\n",
        "# Optimization\n",
        "model_dtype: \"fp16\"\n",
        "optim: \"adam\"\n",
        "learning_rate: 2\n",
        "decay_method: \"noam\"\n",
        "adam_beta2: 0.998\n",
        "max_grad_norm: 0\n",
        "label_smoothing: 0.1\n",
        "param_init: 0\n",
        "param_init_glorot: true\n",
        "normalization: \"tokens\"\n",
        "\n",
        "# Model\n",
        "encoder_type: transformer\n",
        "decoder_type: transformer\n",
        "position_encoding: true\n",
        "enc_layers: 6\n",
        "dec_layers: 6\n",
        "heads: 8\n",
        "hidden_size: 512\n",
        "word_vec_size: 512\n",
        "transformer_ff: 2048\n",
        "dropout_steps: [0]\n",
        "dropout: [0.1]\n",
        "attention_dropout: [0.1]\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "if(GPU):\n",
        "  config += \"\"\"\n",
        "world_size: 1\n",
        "gpu_ranks: [0]\n",
        "  \"\"\"\n",
        "\n",
        "with open(f\"{model_name}/config.yaml\", \"w\") as fp:\n",
        "  fp.write(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tv8QoZU5TZ8l"
      },
      "outputs": [],
      "source": [
        "!nproc --all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HQ3cHg9VItn"
      },
      "outputs": [],
      "source": [
        "!onmt_build_vocab -config {model_name}/config.yaml -n_sample -1 -num_threads 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOjn4RFgKspm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9BJVj8CHluj"
      },
      "outputs": [],
      "source": [
        "!onmt_train -config {model_name}/config.yaml -verbose "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfIt1UXLydh9"
      },
      "outputs": [],
      "source": [
        "ls models/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQHRzhIEZTRC"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-qSMFQ0Za3T"
      },
      "outputs": [],
      "source": [
        "!onmt_translate -model models/fr2bam_step_400.pt -src data/test.sub.fr -output models/nllb.pred_400.txt -gpu 1 -verbose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yupj_BhdNNo"
      },
      "outputs": [],
      "source": [
        "!head data/test.sub.bam \n",
        "!head models/nllb.pred_400.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45lJ9vy6y5w1"
      },
      "outputs": [],
      "source": [
        "!python scripts/desubword.py data/target.model fr2bam/models/nllb.pred_400.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47sp8qSWAt6q"
      },
      "outputs": [],
      "source": [
        "# Sacrebleu testing CODE\n",
        "bleu = !sacrebleu data/test.fr -i fr2bam/models/nllb.pred_400.txt.desub.txt -m bleu -b -w 4\n",
        "ter = !sacrebleu data/test.fr -i fr2bam/models/nllb.pred_400.txt.desub.txt -m ter -b -w 4\n",
        "\n",
        "print(bleu)\n",
        "print(ter)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "onmt",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "3817ddb84c541c333c608c08e8d65a77181da8d4c3693ad20cf54437f03f9188"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
